import os
import numpy as np
import pandas as pd
from skimage.io import imread, imshow, imsave
from PIL import Image
from matplotlib import pyplot as plt
import torch
import torchvision
from torchvision import datasets, transforms
from sklearn.metrics import roc_auc_score, accuracy_score
import sklearn, sklearn.model_selection

import torchxrayvision as xrv
from .base_data_loader import CxrDataset

from snel.transforms import build_transform_aug
from .xrv_datasets import apply_transforms
from .multilabel_sampler import MultilabelBalancedRandomSampler


def build_dataloader_train(cfg, train_mode=True):
    # Dataset split
    # requires dataset class generated by xrv
    tfms_list = build_transform_aug(cfg, is_train=train_mode, choices=None)
    transforms = tfms_list

    if "pdc" in cfg.datasets.name:
        tfms = torchvision.transforms.Compose(
            [torchvision.transforms.ToTensor()])
        dataset = xrv.datasets.PC_Dataset(
                imgpath=cfg.datasets.dataset_dir + "/images-224", 
                csvpath=cfg.datasets.dataset_label_dir + '/PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv',
                transform=tfms, data_aug=None, 
                unique_patients=False, views=["PA","AP"])
        dataset_pathologies = cfg.datasets.finding_names
        xrv.datasets.relabel_dataset(dataset_pathologies, dataset)
        a=1
        
    elif "chex" in cfg.datasets.name:
        dataset = CheX_Dataset_UOnes(
            imgpath=cfg.datasets.dataset_dir + "/CheXpert-v1.0-small",
            csvpath=cfg.datasets.dataset_label_dir + "/chexpert_train.csv",
            transform=transforms, data_aug=None, 
            unique_patients=False, views=["PA","AP"], cfg=cfg)
    elif "nih" in cfg.datasets.name:
        dataset = NIH_Dataset_2017(
            imgpath=cfg.datasets.dataset_dir + "/images",
            csvpath=cfg.datasets.dataset_label_dir+'/NIH_train.csv',
            transform=transforms, data_aug=None, unique_patients=False,
            views=['PA', 'AP'], cfg=cfg)
    else:
        raise NotImplementedError("No Implemented dataset")
    
    if cfg.seed > 0:
        gss = sklearn.model_selection.GroupShuffleSplit(
            train_size=0.8, test_size=0.2, random_state=cfg.seed)
    else:
        gss = sklearn.model_selection.GroupShuffleSplit(
            train_size=0.8, test_size=0.2, random_state=None)
    train_inds, test_inds = next(gss.split(X=range(len(dataset)), groups=dataset.csv.patientid))
    train_dataset = xrv.datasets.SubsetDataset(dataset, train_inds)
    valid_dataset = xrv.datasets.SubsetDataset(dataset, test_inds)
    
    
    train_shuffle = cfg.datasets.train_shuffle
    train_sampler = None
    
    # sampling
    if cfg.datasets.balanced_sampling:
        train_shuffle = False
        train_dataset_indices = list(range(len(train_dataset)))
        np.random.shuffle(train_dataset_indices)
        train_sampler = MultilabelBalancedRandomSampler(
            train_dataset.labels, train_dataset_indices,
            class_choice="cycle")
    else:
        train_dataset_indices = list(range(len(train_dataset)))


    # Dataloader
    train_loader = torch.utils.data.DataLoader(train_dataset,
                                               batch_size=cfg.datasets.train_batch_size,
                                               shuffle=train_shuffle,
                                               num_workers=cfg.datasets.train_num_workers, 
                                               pin_memory=cfg.use_cuda, 
                                               sampler=train_sampler)
    valid_loader = torch.utils.data.DataLoader(valid_dataset,
                                               batch_size=cfg.datasets.test_batch_size,
                                               shuffle=cfg.datasets.test_shuffle,
                                               num_workers=cfg.datasets.test_num_workers, 
                                               pin_memory=cfg.use_cuda)

    return train_loader, valid_loader


def check_each_batch(data_loader):
    for batch in data_loader:
        image = batch["img"]
        labels = batch["lab"]
        
        print("Label counts per class:")
        sum_ = labels.sum(axis=0).numpy()
        print(sum_)
        print("Difference between min and max: ", (max(sum_) - min(sum_)))
        print("")
    print("")


def build_dataloader_test(cfg, train_mode=False):
    # Dataset split
    # requires dataset class generated by xrv
    tfms_list = build_transform_aug(cfg, is_train=train_mode, choices=None)
    transforms = tfms_list

    if "pdc" in cfg.datasets.name:
        dataset = PDC_Dataset(
            imgpath=cfg.datasets.dataset_dir + "/images-224", 
            csvpath=cfg.datasets.dataset_label_dir + '/padchest_test.csv',
            transform=transforms, data_aug=None, 
            unique_patients=False, views=["PA","AP"], cfg=cfg)
    elif "chex" in cfg.datasets.name:
        dataset = CheX_Dataset_UOnes(
            imgpath=cfg.datasets.dataset_dir + "/CheXpert-v1.0-small",
            csvpath=cfg.datasets.dataset_label_dir + "/chexpert_valid.csv",
            transform=transforms, data_aug=None, 
            unique_patients=False, views=["PA","AP"], cfg=cfg)
    elif "nih" in cfg.datasets.name:
        dataset = NIH_Dataset_2017(
            imgpath=cfg.datasets.dataset_dir + "/images",
            csvpath=cfg.datasets.dataset_label_dir+'/NIH_test.csv',
            transform=transforms, data_aug=None, unique_patients=False,
            views=['PA', 'AP'], label_setting=cfg.datasets.no_finding_as_label)
    elif "google_rsna" in cfg.datasets.name:
        dataset = xrv.datasets.NIH_Google_Dataset(
            imgpath=cfg.datasets.dataset_dir + "/images",
            csvpath=cfg.datasets.dataset_label_dir+'/NIH_google_radiology_test_labels.csv',
            transform=transforms, data_aug=None)
    elif "google_scirep" in cfg.datasets.name:
        dataset = NIH_Google_SciRep_Dataset(
            imgpath=cfg.datasets.dataset_dir + "/images",
            csvpath=cfg.datasets.dataset_label_dir + "/NIH_google_scirep_test_labels.csv",
            transform=transforms, data_aug=None, views=['PA', 'AP'], 
            cfg=cfg)
    else:
        print('No dataset')

    # Dataloader
    test_loader = torch.utils.data.DataLoader(dataset,
                                              batch_size=cfg.datasets.test_batch_size,
                                              shuffle=cfg.datasets.test_shuffle,
                                              num_workers=cfg.datasets.test_num_workers,
                                              pin_memory=cfg.use_cuda)

    return test_loader


class NIH_Dataset_2017(CxrDataset):
    """NIH ChestX-ray8 dataset

    Dataset release website:
    https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community

    Download full size images here:
    https://academictorrents.com/details/557481faacd824c83fbf57dcf7b6da9383b3235a

    Download resized (224x224) images here:
    https://academictorrents.com/details/e615d3aebce373f1dc8bd9d11064da55bdadede0
    """

    def __init__(self,
                 imgpath,
                 csvpath,
                 bbox_list_path='../data/BBox_List_2017.csv',
                 views=["PA", "AP"],
                 transform=None,
                 data_aug=None,
                 nrows=None,
                 seed=0,
                 unique_patients=True,
                 pathology_masks=False,
                 cfg=None
                 ):
        super(NIH_Dataset_2017, self).__init__()

        np.random.seed(seed)  # Reset the seed so all runs are the same.
        self.imgpath = imgpath
        self.csvpath = csvpath
        self.transform = transform
        self.data_aug = data_aug
        self.pathology_masks = pathology_masks

        self.pathologies = ["Atelectasis", "Consolidation", "Infiltration",
                            "Pneumothorax", "Edema", "Emphysema", "Fibrosis",
                            "Effusion", "Pneumonia", "Pleural_Thickening",
                            "Cardiomegaly", "Nodule", "Mass", "Hernia"]
        
        if cfg.datasets.finding_names:
            self.pathologies = cfg.datasets.finding_names

        self.pathologies = sorted(self.pathologies)

        # Load data
        self.check_paths_exist()
        self.csv = pd.read_csv(self.csvpath, nrows=nrows)

        # Remove images with view position other than specified
        self.csv["view"] = self.csv['View Position']
        self.limit_to_selected_views(views)

        if unique_patients:
            self.csv = self.csv.groupby("Patient ID").first()

        self.csv = self.csv.reset_index()

        ####### pathology masks ########
        # load nih pathology masks
        self.pathology_maskscsv = pd.read_csv(bbox_list_path,
                                              names=["Image Index", "Finding Label", "x", "y", "w", "h", "_1", "_2", "_3"],
                                              skiprows=1)

        # change label name to match
        self.pathology_maskscsv.loc[self.pathology_maskscsv["Finding Label"] == "Infiltrate", "Finding Label"] = "Infiltration"
        self.csv["has_masks"] = self.csv["Image Index"].isin(self.pathology_maskscsv["Image Index"])

        ####### pathology masks ########
        # Get our classes.
        self.labels = []
        for pathology in self.pathologies:
            self.labels.append(self.csv["Finding Labels"].str.contains(pathology).values)

        self.labels = np.asarray(self.labels).T
        self.labels = self.labels.astype(np.float32)

        # add consistent csv values

        # offset_day_int
        # self.csv["offset_day_int"] =

        # patientid
        self.csv["patientid"] = self.csv["Patient ID"].astype(str)

        # age
        self.csv['age_years'] = self.csv['Patient Age'] * 1.0

        # sex
        self.csv['sex_male'] = self.csv['Patient Gender'] == 'M'
        self.csv['sex_female'] = self.csv['Patient Gender'] == 'F'

    def string(self):
        return self.__class__.__name__ + " num_samples={} views={} data_aug={}".format(len(self), self.views, self.data_aug)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        sample = {}
        sample["idx"] = idx
        sample["lab"] = self.labels[idx]

        imgid = self.csv['Image Index'].iloc[idx]
        img_path = os.path.join(self.imgpath, imgid)
        img = imread(img_path)

        #sample["img"] = normalize(img, maxval=255, reshape=True)

        if self.pathology_masks:
            sample["pathology_masks"] = self.get_mask_dict(imgid, sample["img"].shape[2])

        sample["img"] = Image.fromarray(img).convert('RGB')
        sample = apply_transforms(sample, self.transform)

        return sample

    def get_mask_dict(self, image_name, this_size):
        base_size = 1024
        scale = this_size / base_size

        images_with_masks = self.pathology_maskscsv[self.pathology_maskscsv["Image Index"] == image_name]
        path_mask = {}

        for i in range(len(images_with_masks)):
            row = images_with_masks.iloc[i]

            # Don't add masks for labels we don't have
            if row["Finding Label"] in self.pathologies:
                mask = np.zeros([this_size, this_size])
                xywh = np.asarray([row.x, row.y, row.w, row.h])
                xywh = xywh * scale
                xywh = xywh.astype(int)
                mask[xywh[1]:xywh[1] + xywh[3], xywh[0]:xywh[0] + xywh[2]] = 1

                # Resize so image resizing works
                mask = mask[None, :, :]

                path_mask[self.pathologies.index(row["Finding Label"])] = mask
        return path_mask


class NIH_Google_SciRep_Dataset(CxrDataset):
    """A relabelling of a subset of images from the NIH dataset.  The data tables should
    be applied against an NIH download.  A test and validation split are provided in the
    original.  They are combined here, but one or the other can be used by providing
    the original csv to the csvpath argument.

    Nabulsi, Z., Sellergren, A., Jamshy, S. et al. 
    Deep learning for distinguishing normal versus abnormal chest radiographs and 
    generalization to two unseen diseases tuberculosis and COVID-19. 
    Sci Rep 11, 15523 (2021). 
    
    https://doi.org/10.1038/s41598-021-93967-2
    """

    def __init__(self,
                 imgpath,
                 csvpath,
                 views=["PA"],
                 transform=None,
                 data_aug=None,
                 nrows=None,
                 seed=0,
                 unique_patients=False,
                 cfg=None
                 ):

        super(NIH_Google_SciRep_Dataset, self).__init__()
        np.random.seed(seed)  # Reset the seed so all runs are the same.
        self.imgpath = imgpath
        self.transform = transform
        self.data_aug = data_aug

        self.pathologies = ["Atelectasis", "Consolidation", "Infiltration",
                            "Pneumothorax", "Edema", "Emphysema", "Fibrosis",
                            "Effusion", "Pneumonia", "Pleural_Thickening",
                            "Cardiomegaly", "Nodule", "Mass", "Hernia"]
        
        if cfg.datasets.finding_names:
            self.pathologies = cfg.datasets.finding_names
        self.pathologies = sorted(self.pathologies)
        
        # if label_setting:
        #     self.pathologies.append('Abnormal','Other')

        # Load data
        self.csvpath = csvpath
        self.csv = pd.read_csv(self.csvpath, nrows=nrows)

        # Remove images with view position other than specified
        self.csv["view"] = self.csv['View Position']
        self.limit_to_selected_views(views)

        if unique_patients:
            self.csv = self.csv.groupby("Patient ID").first().reset_index()

        # Get our classes.
        self.labels = []
        for pathology in self.pathologies:
            mask = self.csv[pathology] == "YES"
            self.labels.append(mask.values)
        
        # if label_setting:    
        #     mask = (self.csv['Abnormal'] == "NO") | (self.csv['Other'] == "YES")
        #     self.labels.append(mask.values)

        self.labels = np.asarray(self.labels).T
        self.labels = self.labels.astype(np.float32)

        # rename pathologies
        self.pathologies = list(self.pathologies)

    def string(self):
        return self.__class__.__name__ + " num_samples={} views={} data_aug={}".format(len(self), self.views, self.data_aug)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        sample = {}
        sample["idx"] = idx
        sample["lab"] = self.labels[idx]

        imgid = self.csv['Image ID'].iloc[idx]
        img_path = os.path.join(self.imgpath, imgid)
        img = imread(img_path)

        # Scales images to be roughly [-1024 1024]
        #sample["img"] = xrv_normalize(img, maxval=255, reshape=True)
        sample["img"] = Image.fromarray(img).convert('RGB')

        sample = apply_transforms(sample, self.transform)
        # sample = apply_transforms(sample, self.data_aug)

        return sample
    

class CheX_Dataset_UOnes(CxrDataset):
    """CheXpert Dataset
    Using U-Ones for uncertainty labels

    CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison.
    Jeremy Irvin *, Pranav Rajpurkar *, Michael Ko, Yifan Yu, Silviana Ciurea-Ilcus, Chris Chute,
    Henrik Marklund, Behzad Haghgoo, Robyn Ball, Katie Shpanskaya, Jayne Seekins, David A. Mong,
    Safwan S. Halabi, Jesse K. Sandberg, Ricky Jones, David B. Larson, Curtis P. Langlotz,
    Bhavik N. Patel, Matthew P. Lungren, Andrew Y. Ng. https://arxiv.org/abs/1901.07031

    Dataset website here:
    https://stanfordmlgroup.github.io/competitions/chexpert/

    A small validation set is provided with the data as well, but is so tiny, it not included
    here.
    """

    def __init__(self,
                 imgpath,
                 csvpath,
                 views=["PA"],
                 transform=None,
                 data_aug=None,
                 flat_dir=True,
                 seed=0,
                 unique_patients=True,
                 cfg=None
                 ):

        super(CheX_Dataset_UOnes, self).__init__()
        np.random.seed(seed)  # Reset the seed so all runs are the same.

        self.pathologies = ["No Finding",
                            "Enlarged Cardiomediastinum",
                            "Cardiomegaly",
                            "Lung Opacity",
                            "Lung Lesion",
                            "Edema",
                            "Consolidation",
                            "Pneumonia",
                            "Atelectasis",
                            "Pneumothorax",
                            "Pleural Effusion",
                            "Pleural Other",
                            "Fracture",
                            "Support Devices"]
        
        if cfg.datasets.finding_names:
            self.pathologies = cfg.datasets.finding_names

        self.pathologies = sorted(self.pathologies)

        self.imgpath = imgpath
        self.transform = transform
        self.data_aug = data_aug
        self.csvpath = csvpath
        self.csv = pd.read_csv(self.csvpath)
        self.views = views

        self.csv["view"] = self.csv["Frontal/Lateral"]  # Assign view column
        self.csv.loc[(self.csv["view"] == "Frontal"), "view"] = self.csv["AP/PA"]  # If Frontal change with the corresponding value in the AP/PA column otherwise remains Lateral
        self.csv["view"] = self.csv["view"].replace({'Lateral': "L"})  # Rename Lateral with L

        self.limit_to_selected_views(views)

        if unique_patients:
            self.csv["PatientID"] = self.csv["Path"].str.extract(pat=r'(patient\d+)')
            self.csv = self.csv.groupby("PatientID").first().reset_index()

        # Get our classes.
        healthy = self.csv["No Finding"] == 1
        self.labels = []
        for pathology in self.pathologies:
            if pathology in self.csv.columns:
                if pathology != "Support Devices":
                    self.csv.loc[healthy, pathology] = 0
                mask = self.csv[pathology]

            self.labels.append(mask.values)
        self.labels = np.asarray(self.labels).T
        self.labels = self.labels.astype(np.float32)

        '''
        CheXpert homepage:
        blank for unmentioned (negative), 
        0 for negative, 
        -1 for uncertain, 
        and 1 for positive
        
        U-Ones setting: map all uncertain instances to 1
        '''

        # Make all the -1 values into 1 under the U-Ones setting
        self.labels[self.labels == -1] = 1
        self.labels[pd.isnull(self.labels)] = 0

        # Rename pathologies
        self.pathologies = list(np.char.replace(self.pathologies, "Pleural Effusion", "Effusion"))

        # add consistent csv values

        # offset_day_int

        # patientid
        if 'train' in csvpath:
            patientid = self.csv.Path.str.split("train/", expand=True)[1]
        elif 'valid' in csvpath:
            patientid = self.csv.Path.str.split("valid/", expand=True)[1]
        else:
            raise NotImplemented

        patientid = patientid.str.split("/study", expand=True)[0]
        patientid = patientid.str.replace("patient", "")

        # patientid
        self.csv["patientid"] = patientid

        # age
        self.csv['age_years'] = self.csv['Age'] * 1.0
        self.csv['Age'][(self.csv['Age'] == 0)] = None

        # sex
        self.csv['sex_male'] = self.csv['Sex'] == 'Male'
        self.csv['sex_female'] = self.csv['Sex'] == 'Female'

    def string(self):
        return self.__class__.__name__ + " num_samples={} views={} data_aug={}".format(len(self), self.views, self.data_aug)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        sample = {}
        sample["idx"] = idx
        sample["lab"] = self.labels[idx]

        imgid = self.csv['Path'].iloc[idx]
        imgid = imgid.replace("CheXpert-v1.0-small/", "")
        img_path = os.path.join(self.imgpath, imgid)
        img = imread(img_path)
        #img = Image.open(img_path).convert('RGB')
        # imsave('/home/why/jupyterlab/cxr_nl/fig/'+str(idx)+'.png', img)
        '''
        skimage.io.imread: uint8(unsigned int), numpy array, RGB
        (h, w, c)
        cv2.imread: uint8, numpy array, BGR
        (h, w, c)
        PIL
        (w, h, c)
        '''
        #a_img = self.transform(img_pil)

        #sample["img"] = xrv_normalize(img, maxval=255, reshape=True)
        sample["img"] = Image.fromarray(img).convert('RGB')
        

        sample = apply_transforms(sample, self.transform)
        #sample = apply_transforms(sample, self.data_aug)

        return sample


class PDC_Dataset(CxrDataset):
    """PadChest dataset
    Hospital San Juan de Alicante - University of Alicante

    Note that images with null labels (as opposed to normal), and images that cannot
    be properly loaded (listed as 'missing' in the code) are excluded, which makes
    the total number of available images slightly less than the total number of image
    files.

    PadChest: A large chest x-ray image dataset with multi-label annotated reports.
    Aurelia Bustos, Antonio Pertusa, Jose-Maria Salinas, and Maria de la Iglesia-Vayá.
    arXiv preprint, 2019. https://arxiv.org/abs/1901.07441

    Dataset website:
    http://bimcv.cipf.es/bimcv-projects/padchest/

    Download full size images here:
    https://academictorrents.com/details/dec12db21d57e158f78621f06dcbe78248d14850

    Download resized (224x224) images here (recropped):
    https://academictorrents.com/details/96ebb4f92b85929eadfb16761f310a6d04105797
    """

    def __init__(self,
                 imgpath,
                 csvpath,
                 views=["PA"],
                 transform=None,
                 data_aug=None,
                 flat_dir=True,
                 seed=0,
                 unique_patients=True,
                 cfg=None
                 ):

        super(PDC_Dataset, self).__init__()
        np.random.seed(seed)  # Reset the seed so all runs are the same.

        self.pathologies = ["Atelectasis", "Consolidation", "Infiltration",
                            "Pneumothorax", "Edema", "Emphysema", "Fibrosis",
                            "Effusion", "Pneumonia", "Pleural_Thickening",
                            "Cardiomegaly", "Nodule", "Mass", "Hernia", "Fracture",
                            "Granuloma", "Flattened Diaphragm", "Bronchiectasis",
                            "Aortic Elongation", "Scoliosis",
                            "Hilar Enlargement", "Tuberculosis",
                            "Air Trapping", "Costophrenic Angle Blunting", "Aortic Atheromatosis",
                            "Hemidiaphragm Elevation",
                            "Support Devices", "Tube'"]  # the Tube' is intentional
        
        if cfg.datasets.finding_names:
            self.pathologies = cfg.datasets.finding_names

        self.pathologies = sorted(self.pathologies)

        mapping = dict()

        mapping["Infiltration"] = ["infiltrates",
                                   "interstitial pattern",
                                   "ground glass pattern",
                                   "reticular interstitial pattern",
                                   "reticulonodular interstitial pattern",
                                   "alveolar pattern",
                                   "consolidation",
                                   "air bronchogram"]
        mapping["Pleural_Thickening"] = ["pleural thickening"]
        #mapping["Consolidation"] = ["air bronchogram"]
        mapping["Hilar Enlargement"] = ["adenopathy",
                                        "pulmonary artery enlargement"]
        mapping["Support Devices"] = ["device",
                                      "pacemaker"]
        mapping["Tube'"] = ["stent'"]  # the ' is to select findings which end in that word
        mapping["No Finding"] = ["normal"]
        
        mapping["Atelectasis"] = ['laminar atelectasis', 'fibrotic band', 
                                  'atelectasis', 'lobar atelectasis', 
                                  'segmental atelectasis', 'atelectasis basal', 
                                  'total atelectasis']
        mapping["Cardiomegaly"] = ['cardiomegaly', 'pericardial effusion']

        self.imgpath = imgpath
        self.transform = transform
        self.data_aug = data_aug
        self.flat_dir = flat_dir
        self.csvpath = csvpath

        self.check_paths_exist()
        self.csv = pd.read_csv(self.csvpath, low_memory=False)

        # Standardize view names
        self.csv.loc[self.csv["Projection"].isin(["AP_horizontal"]), "Projection"] = "AP Supine"

        self.csv["view"] = self.csv['Projection']
        self.limit_to_selected_views(views)

        # Remove null stuff
        self.csv = self.csv[~self.csv["Labels"].isnull()]

        # Remove missing files
        missing = ["216840111366964012819207061112010307142602253_04-014-084.png",
                   "216840111366964012989926673512011074122523403_00-163-058.png",
                   "216840111366964012959786098432011033083840143_00-176-115.png",
                   "216840111366964012558082906712009327122220177_00-102-064.png",
                   "216840111366964012339356563862009072111404053_00-043-192.png",
                   "216840111366964013076187734852011291090445391_00-196-188.png",
                   "216840111366964012373310883942009117084022290_00-064-025.png",
                   "216840111366964012283393834152009033102258826_00-059-087.png",
                   "216840111366964012373310883942009170084120009_00-097-074.png",
                   "216840111366964012819207061112010315104455352_04-024-184.png",
                   "216840111366964012819207061112010306085429121_04-020-102.png"]
        self.csv = self.csv[~self.csv["ImageID"].isin(missing)]

        if unique_patients:
            self.csv = self.csv.groupby("PatientID").first().reset_index()

        # Filter out age < 10 (paper published 2019)
        # self.csv = self.csv[(2019 - self.csv.PatientBirth > 10)]

        # Get our classes.
        self.labels = []
        for pathology in self.pathologies:
            mask = self.csv["Labels"].str.contains(pathology.lower())
            if pathology in mapping:
                for syn in mapping[pathology]:
                    #print("mapping", syn)
                    mask |= self.csv["Labels"].str.contains(syn.lower())                   
                    if syn == 'hydropneumothorax':
                        mask = ~self.csv["Labels"].str.contains(syn.lower())
            self.labels.append(mask.values)
        self.labels = np.asarray(self.labels).T
        self.labels = self.labels.astype(np.float32)

        #self.pathologies[self.pathologies.index("Tube'")] = "Tube"

        # add consistent csv values

        # offset_day_int
        dt = pd.to_datetime(self.csv["StudyDate_DICOM"], format="%Y%m%d")
        self.csv["offset_day_int"] = dt.astype(np.int64) // 10**9 // 86400

        # patientid
        self.csv["patientid"] = self.csv["PatientID"].astype(str)

        # age
        self.csv['age_years'] = (2017 - self.csv['PatientBirth'])

        # sex
        self.csv['sex_male'] = self.csv['PatientSex_DICOM'] == 'M'
        self.csv['sex_female'] = self.csv['PatientSex_DICOM'] == 'F'

    def string(self):
        return self.__class__.__name__ + " num_samples={} views={} data_aug={}".format(len(self), self.views, self.data_aug)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        sample = {}
        sample["idx"] = idx
        sample["lab"] = self.labels[idx]

        imgid = self.csv['ImageID'].iloc[idx]
        img_path = os.path.join(self.imgpath, imgid)
        img = imread(img_path)

        #sample["img"] = normalize(img, maxval=65535, reshape=True)
        sample["img"] = Image.fromarray(img).convert('RGB')
        
        sample = apply_transforms(sample, self.transform)

        return sample
